{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models - Examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Driver Risk\n",
    "\n",
    "Credit scores and number of jobs in a year can be used to predict drivers' risk status. Given previous data, we learn that credit scores and number of jobs are distributed by group as follows:\n",
    "\n",
    "- 95% of drivers in the Preferred group have credit scores between 760 and 810. Average number of jobs is 1.\n",
    "- 95% of drivers in the Standard group have credit scores between 670 and 740. Average number of jobs is 3.\n",
    "- 95% of drivers in the High-Risk group have credit scores between 580 and 660. Average number of jobs is 4.\n",
    "\n",
    "Also, we have that 20% of people belong to the Preferred group, 45% belong to the Standard group, and 35% belong to the High-Risk group.\n",
    "\n",
    "If we select a new policyholder that had 2 jobs in the previous year and a credit score between 730 and 770, what is his/her posterior probability of being a High-Risk driver? (assume conditional independence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neoBayesian.models.continuous.normalNormal import *\n",
    "from neoBayesian.tools.routines import *\n",
    "from neoBayesian.models.discrete import PoissonDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the normal distribution to model credit scores.\n",
    "# Given the ranges, we need to find distribution parameters:\n",
    "Pref_p1 = getParamsFromInterval((760, 810), 95)\n",
    "Stan_p2 = getParamsFromInterval((670, 740), 95)\n",
    "High_p3 = getParamsFromInterval((580, 660), 95)\n",
    "\n",
    "# given the parameters we can find the likelihood for each group\n",
    "ls1 = getLikelihood(Pref_p1, (730, 770))\n",
    "ls2 = getLikelihood(Stan_p2, (730, 770))\n",
    "ls3 = getLikelihood(High_p3, (730, 770))\n",
    "\n",
    "# we can use the Poisson distribution to model number of jobs\n",
    "lm1 = PoissonDist(1, 2)\n",
    "lm2 = PoissonDist(3, 2)\n",
    "lm3 = PoissonDist(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type          Preferred    Standard    High-Risk\n",
      "----------  -----------  ----------  -----------\n",
      "Prior         0.2        0.45        0.35\n",
      "Likelihood    0.022034   0.0180623   5.1619e-09\n",
      "Joint         0.0044068  0.00812805  1.80666e-09\n",
      "Posterior     0.351564   0.648436    1.44131e-07\n",
      "\n",
      "Marginal Probability = sum([joint probabilities])\n",
      "= 0.0125\n"
     ]
    }
   ],
   "source": [
    "# we can multiply likelihoods since we are assuming independence.\n",
    "# we use this function to display results in tabular form.\n",
    "tabulateBayesianAlgorithm(\n",
    "    ('Preferred', 0.20, ls1*lm1),\n",
    "    ('Standard', 0.45, ls2*lm2),\n",
    "    ('High-Risk', 0.35, ls3*lm3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Referendum \n",
    "\n",
    "A referendum is about to occur 1 week from now. Marcus and Epictetus are discussing about the probability of a randomly selected person voting YES on this event. They decide to conduct an experiment by asking 30 randomly selected persons in the street if they would vote YES or No. They decide to use the beta-binomial model. Marcus strongly believes that people would mostly vote Yes, so he decides to use 80% and 5% and the mean and variance of the prior beta distribution. Epictetus is totally agnostic so he will use a non-informative prior. After conducting the survey 19 people answer YES. What is the probability that a randomly selected person would vote YES using this data given both priors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neoBayesian.models.continuous.betaBinomial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarcusParams = getMeanVarOrAlphaBeta(mean=0.8, variance=0.1)\n",
    "# Epictetus uses a non-informative prior\n",
    "EpictetusParams = getMeanVarOrAlphaBeta(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 30, k: 19\n",
      "\n",
      "Posterior:\n",
      "\talpha-> 19.48 \n",
      "\tbeta-> 11.12, \n",
      "\texpected-> 0.637 \n",
      "\tvariance-> 0.007.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.48, 11.12, 0.6366013071895424, 0.007320888698547728)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MARCUS results\n",
    "getPosterior(30, 19, MarcusParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 30, k: 19\n",
      "\n",
      "Posterior:\n",
      "\talpha-> 18.75 \n",
      "\tbeta-> 10.75, \n",
      "\texpected-> 0.636 \n",
      "\tvariance-> 0.008.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.75, 10.75, 0.635593220338983, 0.0075939173310853765)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EPICTETUS results\n",
    "getPosterior(30, 19, EpictetusParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Ghosts\n",
    "\n",
    "Albafica invites Kardia to his house and makes the following statement: “There is a high paranormal activity in this house, and 50% of nights you will see a ghost”. Kardia has never seen a ghost and don’t believe what Albafica says; she replies: “You are exaggerating, even if you happened to see 1 ghost 1 night it doesn’t mean that you see ghosts 50% of the time”. Albafica replies: “I literally mean what I say, I see ghosts 50% of the time. You can stay in my house and you will be convinced”. Kardia accepts the challenge and decides to use the beta-binomial model to find the posterior probability of this event. She wants to be really sure that if she happens to see 1 ghost (or a few of them) the following days, this is not just a coincidence. She is skeptical, so she will use 1/30 as the prior mean (she thinks she might be able to observe 1 ghost in 30 days at most) and 0.01 as the variance. How many days would it take for Kardia to change her believes about Albafica’s claim if we assume that, in fact, you can see ghosts in Albafica’s house 50% of all nights? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neoBayesian.models.continuous.betaBinomial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kardiaParams = getMeanVarOrAlphaBeta(1/30, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N    k      Alpha       Beta    Expected    Variance\n",
      "---  ---  ---------  ---------  ----------  ----------\n",
      "  2    1    1.07407    3.14815    0.254386  0.0363205\n",
      "  4    2    3.07407    5.14815    0.373874  0.0253835\n",
      "  6    3    6.07407    8.14815    0.427083  0.0160741\n",
      "  8    4   10.0741    12.1481     0.453333  0.0106718\n",
      " 10    5   15.0741    17.1481     0.467816  0.00749391\n",
      " 12    6   21.0741    23.1481     0.476549  0.00551609\n",
      " 14    7   28.0741    30.1481     0.482188  0.00421603\n",
      " 16    8   36.0741    38.1481     0.486028  0.00332089\n",
      " 18    9   45.0741    47.1481     0.488755  0.00268041\n",
      " 20   10   55.0741    57.1481     0.490759  0.00220729\n",
      " 22   11   66.0741    68.1481     0.492274  0.00184837\n",
      " 24   12   78.0741    80.1481     0.493446  0.00156986\n",
      " 26   13   91.0741    93.1481     0.494371  0.00134956\n",
      " 28   14  105.074    107.148      0.495113  0.00117237\n"
     ]
    }
   ],
   "source": [
    "iterOverK(kardiaParams, 0.5, 0.5*.99, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can roughly take 28 days for Kardia to change her believes (assuming she has seen ghosts for 14 nights). Notice that at day 20 the expected value is already 0.49 or 49%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) A rare disease\n",
    "\n",
    "A rare disease known as Enricks follows a Poisson distribution with parameter 'u' for the number of cases each year. From this year’s data it is known that the expected value and the standard deviation are 27 and 3 respectively. After doing some research data is gathered from 6 previous years and the number of cases are:\n",
    "\n",
    "2012: 20  \n",
    "2013: 18  \n",
    "2014: 22  \n",
    "2015: 25  \n",
    "2016: 26  \n",
    "2017: 26  \n",
    "\n",
    "Calculate the posterior expected value and standard deviation using the Gamma-Poisson model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neoBayesian.models.continuous.gammaPoisson import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value: 24.222\n",
      "Standard Deviation: 1.641\n"
     ]
    }
   ],
   "source": [
    "beta, theta = getMeanVarOrThetaBeta(mean=27, variance=3**2)\n",
    "observations = [20, 18, 22, 25, 26, 26]\n",
    "\n",
    "beta, theta, exp, var = getPosterior(beta, theta, observations)\n",
    "print('Expected Value:', round(exp, 3))\n",
    "print('Standard Deviation:', round(var**0.5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Restaurant revenues\n",
    "\n",
    "Enrique has bought a restaurant and has been told by the previous owner that annual revenues fluctuate in an interval of roughly 20,000.00 with 90% probability, and he believes revenues are normally distributed. He also mentioned that in 2018 the average monthly profit was $20,000.00 with precision of 1/1000000. Enrique is a bit confused about these rough estimations so he decides to ask the previous bookkeeper for exact numbers. All he can get from the bookkeeper is an excel sheet with annual profits from 2008 to 2015. Profits are:\n",
    "\n",
    "2008: 180,000.00  \n",
    "2009: 165,000.00  \n",
    "2010: 190,500.00  \n",
    "2011: 210,300.00  \n",
    "2012: 196,000.00  \n",
    "2013: 187,000.00  \n",
    "2014: 220,400.00  \n",
    "2015: 163,000.00  \n",
    "\n",
    "Assuming the good faith of the previous business owner and bookkeeper, Enrique decides to use the owner's information as a prior and the actual data as the observations. what can Enrique conclude about the actual mean and standard deviation for the distribution of revenues? Calculate a 99% credible interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neoBayesian.models.continuous.normalNormal as nn\n",
    "from numpy import var as npv\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior mean (monthly revenues * 12 months)\n",
    "priorU = 20000 * 12\n",
    "# variance is the inverse of precision\n",
    "priorVar = 1000000\n",
    "\n",
    "# Observations\n",
    "obsList = [180000, 165000, 190500, 210300, 196000, 187000, 220400, 163000]\n",
    "# get variance from values stimated by owner\n",
    "u, obsVar1 = nn.getParamsFromInterval((0, 20000), 90)\n",
    "# get variance from actual observations to compare\n",
    "obsVar2 = npv(obsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = nn.getPosterior(obsList, obsVar1, priorU, priorVar, 99)\n",
    "tp2 = nn.getPosterior(obsList, obsVar2, priorU, priorVar, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance type         expected    variance  confidence interval\n",
      "------------------  ----------  ----------  ------------------------\n",
      "estimated by owner   230928.62   822042.58  (228593.05, 233264.191)\n",
      "from observations    238871.88   977869.18  (236324.546, 241419.218)\n"
     ]
    }
   ],
   "source": [
    "headers = ['variance type', 'expected', 'variance', 'confidence interval']\n",
    "print(tabulate([('estimated by owner',)+(tp1), ('from observations',)+(tp2)], \n",
    "               headers=headers,  floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
